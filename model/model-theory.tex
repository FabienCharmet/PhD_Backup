\label{sec:proving-theory}
We present in this section specific aspects of first order logic theorem proving that will be used later on in this thesis. We will give a brief overview of the first order logic theory and we will then present the basics of theorem proving and several verification mechanisms.

\subsubsection{First order logic}
The first order logic is a formal system describing a theory using declarative propositions, predicates and quantification.

A declarative proposition, also referred to as a clause, is a set of terms  that may be connected together using logical operators.
We illustrate this with the following example:

$P \Rightarrow Q$ means "$P$ implies $Q$``. $P$ and $Q$ are the terms of the clause and $\Rightarrow$ is the logical operator representing implication.

The first order logic admits the following logical operators:

\begin{itemize}
    \item $\forall$: The forall operator, $\forall x\in S$ means for all elements $x$ in set $S$.
    \item $\exists$: The exist operator, $\exists x\in S$ means there exist at least one $x$ in set $S$.
    \item $\neg$: The negation operator, $\neg A$ means then logical negation of A, often noted $\overline{A}$.
    \item $\wedge$: The conjunction operator, $A \wedge B$ means the logical arithmetic A AND B.
    \item $\vee$: The disjunction operator, $A \vee B$ means the logical arithmetic A OR B.
    \item brackets $( )$: Brackets are used to order the resolution of the logical proposition, similarly to traditional arithmetic.
    \item $\Rightarrow$: The implication operator, $A \Rightarrow B$ means A implies B.
    \item $\Leftrightarrow$: The bidirectional implication operator, $A \Leftrightarrow B$ means "A implies B`` AND "B implies A``.
\end{itemize}

Predicates are functions taking a set of terms (variables) as input and returning a binary value, True or False, as an output.

For instance, we can define $P(A,B,C) = A \wedge (B \vee C)$, which would yield for the following example: $P(True,False,True)=True$.

\subsubsection{First order logic Theorem Proving}\textbf{\\}
The purpose of theorem proving is to determine if a set of clauses is satisfiable or unsatisfiable.
A satisfiable clause that admits a solution that makes it true.
An unsatisfiable clause is a clause that cannot be true no matter the values of its terms.
The theorem prover will apply inference rules on the original set of clauses and try to reach another set of clauses where the satisfiability can be determined.

We will now present some rules of inference used for first order logic theorem proving.
A rule of inference is a rule defining the deduction process, it takes a set of propositions as input and returns a proposition which is a conclusion drawn from the input propositions.

We use \{clause 1, clause2, ..., clause n\} to define a set of n clauses.\\
We use $\vdash$ to represent the result of the deduction from a set of clauses.

\subsubsection{Modus ponens and modus tollens}\textbf{\\}
Modus ponens is a rule of inference using the affirmation in an implication to deduce the conclusion.
Considering the simple example given previously, $P \Rightarrow Q$, if we assert that $P$ is true, then we use modus ponens to conclude that $Q$ is true as well. This is summarized as ``If P implies Q and P is true, then Q must be true" : $P \Rightarrow Q, P \vdash Q$.

Similarly Modus tollens uses the negation in the consequence of an implication to deduce the conclusion.
Considering $P \Rightarrow Q$, asserting that $Q$ is false, then $P$ must be false as well: $P \Rightarrow Q, \neg Q \vdash \neg P$.

\subsubsection{Resolution principle}\textbf{\\}
The resolution principle, shortened to resolution, is an inference rule satisfying the completeness property. Completeness implies that applying the resolution to an unsatisfiable clause will always yield false. 

For instance, $P \wedge \neg P$ is obviously unsatisfiable, \ie it is always False.

The resolution principle uses substitution in a set of clauses to reach a conclusion.
We consider the simple example presented in~\cite{snark-Stickel2000} and refer the reader to~\cite{symbolic-proof} for additional reading, more specifically on variable unification.
We also refer the reader to the Method of Davis and Putnam and more specifically on the One-Literal Rule.

Consider the following clauses: $\{\neg P \vee Q,P \vee R\}$.\\
The resolution principle returns the clause $Q \vee R$ as a resolvent of the previous propositions.


\subsubsection{Paramodulation}\textbf{\\}
The paramodulation is an inference rule used to exploit the equality existing between terms and the occurrence of term in a proposition. The paramodulation can be seen as \textit{substitution in case of equality}.

Consider the proposition $P(x) = true$ and the quality $x=y$. Therefore, we can infer that $P(y)$ will also yield True.

Consider now the two propositions: $\{P(x) \vee Q(y)$, $(x = y) \vee R(y)\}$.\\
Paramodulation deduces the proposition $P(y) \vee Q(y) \vee R(y)$.\\
$\{P(x) \vee Q(y)$, $(x = y) \vee R(y)\} \vdash P(y) \vee Q(y) \vee R(y)$

\subsubsection{Rewriting rules}\textbf{\\}
Rewriting rules are used to replace an expression by another in a set of propositions.
This is done to simplify the search space when applying inference rules~\cite{snark-Stickel2000}.

We illustrate this with a simple example:\\
$\{P \Leftrightarrow Q \wedge R, P \vee T\}$ is rewritten as $Q \wedge R \vee T$. 

The rewriting rule may be condition to replace the left hand side of an equivalence by the other, but may also apply substitutions to terms in the proposition only on one side of the proposition.
We also refer the reader to~\cite{snark-Stickel2000,symbolic-proof} for further explanations.
